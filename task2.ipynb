{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b4c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 00:19:27,958 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "2025-09-07 00:19:28,257 - INFO - Use pytorch device_name: cpu\n",
      "2025-09-07 00:19:28,262 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Process 1 ---------------------------------------   \n",
      "{'main_topic': 'Projectile Motion', 'context_object': 'Cricket Ball', 'learning_objectives': ['Define projectile motion and identify its key characteristics.', 'Analyze the two-dimensional nature of projectile motion using vector decomposition.', \"Formulate and solve mathematical equations describing the horizontal and vertical components of a projectile's motion.\", 'Apply the principles of kinematics and Newtonian mechanics to predict the trajectory of a projectile.', 'Evaluate the effects of air resistance and initial launch conditions on projectile motion.'], 'prerequisites': ['Understanding of vectors and basic kinematics.', \"Familiarity with Newton's laws of motion.\", 'Knowledge of elementary trigonometric functions.', 'Basic algebraic manipulation and equation solving skills.'], 'concepts': [{'id': 1, 'name': 'Definition of Projectile Motion', 'brief': [\"Projectile motion describes the curved path an object follows when thrown, launched, or projected near the Earth's surface under the influence of gravity alone (assuming air resistance is negligible).\", 'A projectile is any object that moves through space acted on only by gravity (after initial launch impulse).', 'This motion occurs in two dimensions: horizontal (x-axis) and vertical (y-axis).']}, {'id': 2, 'name': 'Independence of Horizontal and Vertical Motion', 'brief': ['The motion can be decomposed into independent horizontal and vertical components.', 'Horizontal motion experiences constant velocity (neglecting air resistance) because no horizontal forces act after projection.', 'Vertical motion is uniformly accelerated due to gravity, resulting in a symmetric path (parabolic shape).']}, {'id': 3, 'name': 'Kinematic Equations for Projectile Motion', 'brief': ['Horizontal displacement: x = v₀x * t, where v₀x is the initial horizontal velocity component.', 'Vertical displacement: y = v₀y * t - (1/2)gt², where v₀y is the initial vertical velocity component and g is the acceleration due to gravity (≈9.8 m/s², downward).', 'Time of flight, maximum height, and range can be calculated using these kinematic equations.']}, {'id': 4, 'name': 'Initial Velocity and Angle of Projection', 'brief': ['The initial velocity (v₀) can be separated into horizontal (v₀x = v₀ * cosθ) and vertical (v₀y = v₀ * sinθ) components using trigonometric relationships, where θ is the launch angle.', 'The launch angle directly influences the maximum height and range of the projectile.', 'Maximum horizontal range is achieved at a launch angle of 45°, in the absence of air resistance.']}, {'id': 5, 'name': 'Trajectory and Parabolic Path', 'brief': ['The combined effect of constant horizontal velocity and uniformly accelerated vertical motion results in a parabolic trajectory.', 'This path is symmetric about the apex (highest point), where the vertical velocity is temporarily zero.', 'The equation for the path: y = (tanθ)x - (g/2v₀²cos²θ)x², represents a parabola in the x-y coordinate plane.']}, {'id': 6, 'name': 'Forces Acting on the Projectile', 'brief': ['After launch, the only significant force acting on the projectile is gravity (downward).', 'Neglecting air resistance simplifies analysis but in reality, air drag can reduce range and alter trajectory.', 'The absence of horizontal force (in ideal conditions) means no change in horizontal velocity during flight.']}, {'id': 7, 'name': 'Air Resistance and Real-World Considerations', 'brief': ['Air resistance opposes motion, causing deviations from the ideal parabolic path and reducing range.', 'The effect of air resistance increases with speed, surface area, and shape of the projectile.', 'In real applications, such as sports, calculations must sometimes include a drag coefficient and other corrective factors to accurately predict motion.']}, {'id': 8, 'name': 'Energy Transformations in Projectile Motion', 'brief': ['At launch, a projectile has kinetic energy due to its speed.', 'As the projectile rises, kinetic energy is transferred into gravitational potential energy until the apex is reached.', 'As it falls, potential energy converts back into kinetic energy due to acceleration by gravity, with maximum kinetic energy just before impact (neglecting losses to air resistance).']}, {'id': 9, 'name': 'Vector Representation and Analysis', 'brief': ['Initial velocity, displacement, and acceleration are vector quantities and require magnitude and direction for complete description.', 'Vector addition and resolution into orthogonal (perpendicular) components are essential for accurate analysis.', 'Graphical methods (such as vector diagrams) and analytical (trigonometric) methods are used for decomposition.']}]}\n",
      "key is  class_10\n",
      "rag\\class_10\n",
      "rag type is  <class 'str'>\n",
      "rag context is :  [1] Q U E S T I O N S 1. What is the difference between a reflex action and walking? 2. What happens at the synapse between two neurons? 3. Which part of the brain maintains posture and equilibrium of the body? 4. How do we detect the smell of an agarbatti (incense stick)? 5. What is the role of the brain in reflex action?\n",
      "context input is :  Main Topic: Projectile Motion\n",
      "Context Object: Cricket Ball\n",
      "Level: High School\n",
      "Concepts: ['Definition of Projectile Motion', 'Independence of Horizontal and Vertical Motion', 'Kinematic Equations for Projectile Motion', 'Initial Velocity and Angle of Projection', 'Trajectory and Parabolic Path', 'Forces Acting on the Projectile', 'Air Resistance and Real-World Considerations', 'Energy Transformations in Projectile Motion', 'Vector Representation and Analysis']\n",
      "RAG_CONTEXT_BEGIN\n",
      "[1] Q U E S T I O N S 1. What is the difference between a reflex action and walking? 2. What happens at the synapse between two neurons? 3. Which part of the brain maintains posture and equilibrium of the body? 4. How do we detect the smell of an agarbatti (incense stick)? 5. What is the role of the brain in reflex action?\n",
      "RAG_CONTEXT_END\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 00:20:16,438 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "========================================\n",
      "Input: ('explain me projectile motion using cricket', '10')\n",
      "========================================\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\tSlide No. - 1\n",
      "\tName : Definition of Projectile Motion\n",
      "\tDetailed Explantion :-\n",
      "\tProjectile motion refers to the curved path an object follows when it is thrown or propelled near the surface of the Earth, subject only to gravity and its initial velocity. Using a cricket ball as our context, when a player throws or hits the ball into the air, it follows a distinct arc before landing on the ground. This type of motion occurs because, after the initial force, gravity is the main factor influencing the ball's movement. Although the RAG_CONTEXT details neural control and reflexes, it does not directly relate to projectile motion, but reminds us that a player's actions (like throwing) may start with a reflex or conscious movement, which sets the cricket ball on its path as a projectile.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 00:20:56,797 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-07 00:22:31,606 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 905\u001b[0m\n\u001b[0;32m    904\u001b[0m     loop \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mget_event_loop()\n\u001b[1;32m--> 905\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstage3_run_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOUTDIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEFAULT_MODEL_STAGE3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAX_PARALLEL_STAGE3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    907\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;66;03m# Fallback for environments without a running loop\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\nest_asyncio.py:98\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\extramarks\\Lib\\asyncio\\futures.py:199\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\extramarks\\Lib\\asyncio\\tasks.py:304\u001b[0m, in \u001b[0;36mTask.__step_run_and_handle_result\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[2], line 720\u001b[0m, in \u001b[0;36mstage3_run_async\u001b[1;34m(items, outdir, model, max_parallel)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fut \u001b[38;5;129;01min\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mas_completed(tasks):\n\u001b[1;32m--> 720\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[0;32m    721\u001b[0m     tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] slide=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mslide_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m «\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mslide_name\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m»\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\extramarks\\Lib\\asyncio\\tasks.py:634\u001b[0m, in \u001b[0;36m_AsCompletedIterator._wait_for_one\u001b[1;34m(self, resolve)\u001b[0m\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTimeoutError\n\u001b[1;32m--> 634\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m resolve \u001b[38;5;28;01melse\u001b[39;00m f\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\extramarks\\Lib\\asyncio\\futures.py:199\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\extramarks\\Lib\\asyncio\\tasks.py:304\u001b[0m, in \u001b[0;36mTask.__step_run_and_handle_result\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[2], line 680\u001b[0m, in \u001b[0;36m_gen_one_figure\u001b[1;34m(client_async, semaphore, model, topic_input, slide, outdir, attempt, max_attempts)\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;66;03m# Execute it\u001b[39;00m\n\u001b[1;32m--> 680\u001b[0m rc, so, se \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m _execute_generated_code(lang, workdir, codefile\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m    681\u001b[0m images \u001b[38;5;241m=\u001b[39m _extract_saved_files(workdir)\n",
      "Cell \u001b[1;32mIn[2], line 598\u001b[0m, in \u001b[0;36m_execute_generated_code\u001b[1;34m(lang, workdir, filename)\u001b[0m\n\u001b[0;32m    597\u001b[0m     cmd \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m, filename]\n\u001b[1;32m--> 598\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _run_subprocess(cmd, workdir)\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lang \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "Cell \u001b[1;32mIn[2], line 585\u001b[0m, in \u001b[0;36m_run_subprocess\u001b[1;34m(cmd, cwd, timeout)\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_subprocess\u001b[39m(cmd: List[\u001b[38;5;28mstr\u001b[39m], cwd: Path, timeout: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 585\u001b[0m     proc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_subprocess_exec(\n\u001b[0;32m    586\u001b[0m         \u001b[38;5;241m*\u001b[39mcmd, cwd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(cwd), stdout\u001b[38;5;241m=\u001b[39masyncio\u001b[38;5;241m.\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE, stderr\u001b[38;5;241m=\u001b[39masyncio\u001b[38;5;241m.\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE\n\u001b[0;32m    587\u001b[0m     )\n\u001b[0;32m    588\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\extramarks\\Lib\\asyncio\\subprocess.py:224\u001b[0m, in \u001b[0;36mcreate_subprocess_exec\u001b[1;34m(program, stdin, stdout, stderr, limit, *args, **kwds)\u001b[0m\n\u001b[0;32m    222\u001b[0m protocol_factory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m: SubprocessStreamProtocol(limit\u001b[38;5;241m=\u001b[39mlimit,\n\u001b[0;32m    223\u001b[0m                                                     loop\u001b[38;5;241m=\u001b[39mloop)\n\u001b[1;32m--> 224\u001b[0m transport, protocol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m loop\u001b[38;5;241m.\u001b[39msubprocess_exec(\n\u001b[0;32m    225\u001b[0m     protocol_factory,\n\u001b[0;32m    226\u001b[0m     program, \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m    227\u001b[0m     stdin\u001b[38;5;241m=\u001b[39mstdin, stdout\u001b[38;5;241m=\u001b[39mstdout,\n\u001b[0;32m    228\u001b[0m     stderr\u001b[38;5;241m=\u001b[39mstderr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Process(transport, protocol, loop)\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\extramarks\\Lib\\asyncio\\base_events.py:1794\u001b[0m, in \u001b[0;36mBaseEventLoop.subprocess_exec\u001b[1;34m(self, protocol_factory, program, stdin, stdout, stderr, universal_newlines, shell, bufsize, encoding, errors, text, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1793\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_subprocess(debug_log, stdin, stdout, stderr)\n\u001b[1;32m-> 1794\u001b[0m transport \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_subprocess_transport(\n\u001b[0;32m   1795\u001b[0m     protocol, popen_args, \u001b[38;5;28;01mFalse\u001b[39;00m, stdin, stdout, stderr,\n\u001b[0;32m   1796\u001b[0m     bufsize, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_debug \u001b[38;5;129;01mand\u001b[39;00m debug_log \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\extramarks\\Lib\\asyncio\\base_events.py:539\u001b[0m, in \u001b[0;36mBaseEventLoop._make_subprocess_transport\u001b[1;34m(self, protocol, args, shell, stdin, stdout, stderr, bufsize, extra, **kwargs)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create subprocess transport.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 539\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 910\u001b[0m\n\u001b[0;32m    905\u001b[0m     results \u001b[38;5;241m=\u001b[39m loop\u001b[38;5;241m.\u001b[39mrun_until_complete(\n\u001b[0;32m    906\u001b[0m         stage3_run_async(items, OUTDIR, DEFAULT_MODEL_STAGE3, MAX_PARALLEL_STAGE3)\n\u001b[0;32m    907\u001b[0m     )\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;66;03m# Fallback for environments without a running loop\u001b[39;00m\n\u001b[1;32m--> 910\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstage3_run_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOUTDIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEFAULT_MODEL_STAGE3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAX_PARALLEL_STAGE3\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    912\u001b[0m summary_path \u001b[38;5;241m=\u001b[39m Path(OUTDIR) \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary_results.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    913\u001b[0m summary_path\u001b[38;5;241m.\u001b[39mwrite_text(json\u001b[38;5;241m.\u001b[39mdumps(results, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m), encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\nest_asyncio.py:98\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\extramarks\\Lib\\asyncio\\futures.py:199\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\extramarks\\Lib\\asyncio\\tasks.py:304\u001b[0m, in \u001b[0;36mTask.__step_run_and_handle_result\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[0;32m    303\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    306\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "Cell \u001b[1;32mIn[2], line 720\u001b[0m, in \u001b[0;36mstage3_run_async\u001b[1;34m(items, outdir, model, max_parallel)\u001b[0m\n\u001b[0;32m    718\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fut \u001b[38;5;129;01min\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mas_completed(tasks):\n\u001b[1;32m--> 720\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[0;32m    721\u001b[0m     tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] slide=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mslide_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m «\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mslide_name\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m»\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\extramarks\\Lib\\asyncio\\tasks.py:634\u001b[0m, in \u001b[0;36m_AsCompletedIterator._wait_for_one\u001b[1;34m(self, resolve)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;66;03m# Dummy value from _handle_timeout().\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTimeoutError\n\u001b[1;32m--> 634\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m resolve \u001b[38;5;28;01melse\u001b[39;00m f\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\extramarks\\Lib\\asyncio\\futures.py:199\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\extramarks\\Lib\\asyncio\\tasks.py:304\u001b[0m, in \u001b[0;36mTask.__step_run_and_handle_result\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[0;32m    303\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    306\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "Cell \u001b[1;32mIn[2], line 680\u001b[0m, in \u001b[0;36m_gen_one_figure\u001b[1;34m(client_async, semaphore, model, topic_input, slide, outdir, attempt, max_attempts)\u001b[0m\n\u001b[0;32m    677\u001b[0m codefile\u001b[38;5;241m.\u001b[39mwrite_text(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mrstrip() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;66;03m# Execute it\u001b[39;00m\n\u001b[1;32m--> 680\u001b[0m rc, so, se \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m _execute_generated_code(lang, workdir, codefile\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m    681\u001b[0m images \u001b[38;5;241m=\u001b[39m _extract_saved_files(workdir)\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    684\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m\"\u001b[39m: rc \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(images) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m: topic_input,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    695\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_json\u001b[39m\u001b[38;5;124m\"\u001b[39m: data\n\u001b[0;32m    696\u001b[0m }\n",
      "Cell \u001b[1;32mIn[2], line 598\u001b[0m, in \u001b[0;36m_execute_generated_code\u001b[1;34m(lang, workdir, filename)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lang \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    597\u001b[0m     cmd \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m, filename]\n\u001b[1;32m--> 598\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _run_subprocess(cmd, workdir)\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lang \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    600\u001b[0m     cmd \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRscript\u001b[39m\u001b[38;5;124m\"\u001b[39m, filename]\n",
      "Cell \u001b[1;32mIn[2], line 585\u001b[0m, in \u001b[0;36m_run_subprocess\u001b[1;34m(cmd, cwd, timeout)\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_subprocess\u001b[39m(cmd: List[\u001b[38;5;28mstr\u001b[39m], cwd: Path, timeout: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 585\u001b[0m     proc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_subprocess_exec(\n\u001b[0;32m    586\u001b[0m         \u001b[38;5;241m*\u001b[39mcmd, cwd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(cwd), stdout\u001b[38;5;241m=\u001b[39masyncio\u001b[38;5;241m.\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE, stderr\u001b[38;5;241m=\u001b[39masyncio\u001b[38;5;241m.\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE\n\u001b[0;32m    587\u001b[0m     )\n\u001b[0;32m    588\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    589\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mwait_for(proc\u001b[38;5;241m.\u001b[39mcommunicate(), timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\extramarks\\Lib\\asyncio\\subprocess.py:224\u001b[0m, in \u001b[0;36mcreate_subprocess_exec\u001b[1;34m(program, stdin, stdout, stderr, limit, *args, **kwds)\u001b[0m\n\u001b[0;32m    221\u001b[0m loop \u001b[38;5;241m=\u001b[39m events\u001b[38;5;241m.\u001b[39mget_running_loop()\n\u001b[0;32m    222\u001b[0m protocol_factory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m: SubprocessStreamProtocol(limit\u001b[38;5;241m=\u001b[39mlimit,\n\u001b[0;32m    223\u001b[0m                                                     loop\u001b[38;5;241m=\u001b[39mloop)\n\u001b[1;32m--> 224\u001b[0m transport, protocol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m loop\u001b[38;5;241m.\u001b[39msubprocess_exec(\n\u001b[0;32m    225\u001b[0m     protocol_factory,\n\u001b[0;32m    226\u001b[0m     program, \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m    227\u001b[0m     stdin\u001b[38;5;241m=\u001b[39mstdin, stdout\u001b[38;5;241m=\u001b[39mstdout,\n\u001b[0;32m    228\u001b[0m     stderr\u001b[38;5;241m=\u001b[39mstderr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Process(transport, protocol, loop)\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\extramarks\\Lib\\asyncio\\base_events.py:1794\u001b[0m, in \u001b[0;36mBaseEventLoop.subprocess_exec\u001b[1;34m(self, protocol_factory, program, stdin, stdout, stderr, universal_newlines, shell, bufsize, encoding, errors, text, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1792\u001b[0m     debug_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexecute program \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprogram\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1793\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_subprocess(debug_log, stdin, stdout, stderr)\n\u001b[1;32m-> 1794\u001b[0m transport \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_subprocess_transport(\n\u001b[0;32m   1795\u001b[0m     protocol, popen_args, \u001b[38;5;28;01mFalse\u001b[39;00m, stdin, stdout, stderr,\n\u001b[0;32m   1796\u001b[0m     bufsize, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_debug \u001b[38;5;129;01mand\u001b[39;00m debug_log \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1798\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m, debug_log, transport)\n",
      "File \u001b[1;32mc:\\Users\\kshit\\anaconda3\\envs\\extramarks\\Lib\\asyncio\\base_events.py:539\u001b[0m, in \u001b[0;36mBaseEventLoop._make_subprocess_transport\u001b[1;34m(self, protocol, args, shell, stdin, stdout, stderr, bufsize, extra, **kwargs)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_make_subprocess_transport\u001b[39m(\u001b[38;5;28mself\u001b[39m, protocol, args, shell,\n\u001b[0;32m    536\u001b[0m                                      stdin, stdout, stderr, bufsize,\n\u001b[0;32m    537\u001b[0m                                      extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    538\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create subprocess transport.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 539\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os \n",
    "import sys \n",
    "import asyncio \n",
    "from pathlib import Path\n",
    "import base64\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import List, Dict, Optional, Tuple , Any\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "# ---------------------------\n",
    "# OpenAI client (env-based)\n",
    "# ---------------------------\n",
    "# IMPORTANT: export OPENAI_API_KEY in your shell; do NOT hardcode keys.\n",
    "from openai import OpenAI , AsyncOpenAI\n",
    "client = OpenAI(api_key='sk-proj--Br-2ucFM_qeDf2qH_QZfp30GMqhQCG5svK4A') # reads OPENAI_API_KEY from env\n",
    "\n",
    "# Your stored prompt IDs (kept as-is)\n",
    "PROMPT_ID_STAGE1 = \"pmpt_689fe50530588190868f3ae35bf6bba60a46b8c35dbea247\"  # High-school structure extractor\n",
    "PROMPT_ID_STAGE2 = \"pmpt_689fee5df6648194954f2011ae66901b0bf49909c48897bd\"  # Context -> detailed explanations\n",
    "OUTDIR = os.getenv(\"OUTDIR\", \"viz_outputs_temp\")\n",
    "MAX_PARALLEL_STAGE3 = int(os.getenv(\"MAX_PARALLEL_STAGE3\", \"6\"))\n",
    "MODEL_STAGE3  = os.getenv(\"OPENAI_MODEL_STAGE3\",  \"gpt-5\")\n",
    "\n",
    "# ===========================\n",
    "# Embedded RAG implementation\n",
    "# (formerly in a separate file)\n",
    "# ===========================\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import List as _List, Dict as _Dict, Optional as _Optional\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Docling LangChain integration\n",
    "from langchain_docling import DoclingLoader\n",
    "from langchain_docling.loader import ExportType\n",
    "from docling.chunking import HybridChunker\n",
    "\n",
    "# Vector store\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "\n",
    "class LangChainDoclingRAG:\n",
    "    \"\"\"RAG system using LangChain with Docling for PDF extraction and semantic search\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_model: str = \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        chunk_size: int = 800,\n",
    "        chunk_overlap: int = 100,\n",
    "        export_type: ExportType = ExportType.DOC_CHUNKS,\n",
    "        persist_directory: _Optional[str] = None,\n",
    "        max_token_length: int = 450  # ~512 for MiniLM\n",
    "    ):\n",
    "        self.embedding_model_name = embedding_model\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.export_type = export_type\n",
    "        self.persist_directory = persist_directory or mkdtemp()\n",
    "        self.max_token_length = max_token_length\n",
    "\n",
    "        self.embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=embedding_model,\n",
    "            encode_kwargs={'normalize_embeddings': True}\n",
    "        )\n",
    "        self.vectorstore = None\n",
    "        self.retriever = None\n",
    "        self.documents = []\n",
    "\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            length_function=len,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "        )\n",
    "\n",
    "    def _estimate_tokens(self, text: str) -> int:\n",
    "        return len(text) // 4\n",
    "\n",
    "    def _truncate_long_documents(self, documents: _List[Document], max_length: int = None) -> _List[Document]:\n",
    "        if max_length is None:\n",
    "            max_length = self.max_token_length * 4\n",
    "        processed_docs = []\n",
    "        for doc in documents:\n",
    "            if self._estimate_tokens(doc.page_content) > self.max_token_length:\n",
    "                content = doc.page_content.strip()\n",
    "                sentences = content.split('. ')\n",
    "                chunks, current = [], \"\"\n",
    "                for sentence in sentences:\n",
    "                    sentence = sentence.strip() + '. '\n",
    "                    if self._estimate_tokens(current + sentence) > self.max_token_length:\n",
    "                        if current:\n",
    "                            chunks.append(current.strip())\n",
    "                            overlap = current.split('. ')[-2:]\n",
    "                            current = ('. '.join(overlap) + '. ' if overlap and overlap[0] else '') + sentence\n",
    "                        else:\n",
    "                            current = sentence\n",
    "                    else:\n",
    "                        current += sentence\n",
    "                if current.strip():\n",
    "                    chunks.append(current.strip())\n",
    "                for i, chunk_content in enumerate(chunks):\n",
    "                    if len(chunk_content.strip()) > 20:\n",
    "                        processed_docs.append(\n",
    "                            Document(page_content=chunk_content, metadata={**doc.metadata, 'chunk_index': i, 'is_split': True})\n",
    "                        )\n",
    "            else:\n",
    "                processed_docs.append(doc)\n",
    "        return processed_docs\n",
    "\n",
    "    def extract_documents_from_pdfs(self, pdf_paths: _List[str]) -> _List[Document]:\n",
    "        all_docs = []\n",
    "        for pdf_path in pdf_paths:\n",
    "            try:\n",
    "                if self.export_type == ExportType.DOC_CHUNKS:\n",
    "                    loader = DoclingLoader(\n",
    "                        file_path=[pdf_path],\n",
    "                        export_type=self.export_type,\n",
    "                        chunker=HybridChunker(tokenizer=self.embedding_model_name)\n",
    "                    )\n",
    "                else:\n",
    "                    loader = DoclingLoader(file_path=[pdf_path], export_type=self.export_type)\n",
    "\n",
    "                docs = loader.load()\n",
    "                for doc in docs:\n",
    "                    doc.metadata.update({'source_file': os.path.basename(pdf_path), 'full_path': pdf_path})\n",
    "                    if 'doc_items' in doc.metadata:\n",
    "                        try:\n",
    "                            doc_items = doc.metadata['doc_items']\n",
    "                            if isinstance(doc_items, list) and doc_items:\n",
    "                                first = doc_items[0]\n",
    "                                if 'prov' in first and isinstance(first['prov'], list) and first['prov']:\n",
    "                                    prov = first['prov'][0]\n",
    "                                    if 'page_no' in prov: doc.metadata['page_number'] = prov['page_no']\n",
    "                                    if 'bbox' in prov:\n",
    "                                        bbox = prov['bbox']\n",
    "                                        doc.metadata['bbox_left'] = bbox.get('l', 0)\n",
    "                                        doc.metadata['bbox_top'] = bbox.get('t', 0)\n",
    "                                        doc.metadata['bbox_right'] = bbox.get('r', 0)\n",
    "                                        doc.metadata['bbox_bottom'] = bbox.get('b', 0)\n",
    "                                if 'label' in first: doc.metadata['content_type'] = first['label']\n",
    "                                if 'content_layer' in first: doc.metadata['content_layer'] = first['content_layer']\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                    if 'origin' in doc.metadata and isinstance(doc.metadata['origin'], dict):\n",
    "                        origin = doc.metadata['origin']\n",
    "                        if 'filename' in origin: doc.metadata['original_filename'] = origin['filename']\n",
    "                        if 'mimetype' in origin: doc.metadata['mimetype'] = origin['mimetype']\n",
    "\n",
    "                if self.export_type == ExportType.DOC_CHUNKS:\n",
    "                    processed_docs = docs\n",
    "                elif self.export_type == ExportType.MARKDOWN:\n",
    "                    from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "                    header_splitter = MarkdownHeaderTextSplitter(\n",
    "                        headers_to_split_on=[(\"#\", \"Header_1\"), (\"##\", \"Header_2\"), (\"###\", \"Header_3\")]\n",
    "                    )\n",
    "                    processed_docs = []\n",
    "                    for doc in docs:\n",
    "                        splits = header_splitter.split_text(doc.page_content)\n",
    "                        for split in splits:\n",
    "                            processed_docs.append(Document(page_content=split.page_content, metadata={**doc.metadata, **split.metadata}))\n",
    "                else:\n",
    "                    processed_docs = self.text_splitter.split_documents(docs)\n",
    "\n",
    "                all_docs.extend(processed_docs)\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error processing {pdf_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "        if all_docs:\n",
    "            all_docs = filter_complex_metadata(all_docs)\n",
    "            all_docs = self._truncate_long_documents(all_docs)\n",
    "\n",
    "        self.documents = all_docs\n",
    "        return all_docs\n",
    "\n",
    "    def build_vector_store(self, documents: _Optional[_List[Document]] = None):\n",
    "        if documents is None:\n",
    "            documents = self.documents\n",
    "        if not documents:\n",
    "            raise ValueError(\"No documents to index. Extract documents first.\")\n",
    "\n",
    "        documents = filter_complex_metadata(documents)\n",
    "        self.vectorstore = Chroma.from_documents(\n",
    "            documents=documents,\n",
    "            embedding=self.embeddings,\n",
    "            persist_directory=self.persist_directory,\n",
    "            collection_name=\"docling_rag\"\n",
    "        )\n",
    "        self.retriever = self.vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "\n",
    "    def add_pdf_to_index(self, pdf_path: str):\n",
    "        new_docs = self.extract_documents_from_pdfs([pdf_path])\n",
    "        if new_docs:\n",
    "            new_docs = filter_complex_metadata(new_docs)\n",
    "            if self.vectorstore is None:\n",
    "                self.build_vector_store(new_docs)\n",
    "            else:\n",
    "                self.vectorstore.add_documents(new_docs)\n",
    "\n",
    "    def search(self, query: str, top_k: int = 5) -> _List[_Dict]:\n",
    "        if self.vectorstore is None:\n",
    "            raise ValueError(\"Vector store not built/loaded. Call load_existing_vectorstore() first.\")\n",
    "        docs_with_scores = self.vectorstore.similarity_search_with_score(query, k=top_k)\n",
    "        results = []\n",
    "        for doc, score in docs_with_scores:\n",
    "            results.append({\n",
    "                'text': doc.page_content,\n",
    "                'source': doc.metadata.get('source_file', 'Unknown'),\n",
    "                'score': float(1 - score),\n",
    "                'metadata': doc.metadata\n",
    "            })\n",
    "        return results\n",
    "\n",
    "    def setup_rag_chain(self, llm, prompt_template: _Optional[str] = None):\n",
    "        if self.retriever is None:\n",
    "            raise ValueError(\"Retriever not set up. Call build_vector_store() first.\")\n",
    "        if prompt_template is None:\n",
    "            prompt_template = \"\"\"Context information is below.\n",
    "---------------------\n",
    "{context}\n",
    "---------------------\n",
    "Given the context information and not prior knowledge, answer the query.\n",
    "Query: {input}\n",
    "Answer:\"\"\"\n",
    "        prompt = PromptTemplate.from_template(prompt_template)\n",
    "        question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "        self.rag_chain = create_retrieval_chain(self.retriever, question_answer_chain)\n",
    "        return self.rag_chain\n",
    "\n",
    "    def ask(self, question: str) -> _Dict:\n",
    "        if not hasattr(self, 'rag_chain'):\n",
    "            raise ValueError(\"RAG chain not set up. Call setup_rag_chain() first.\")\n",
    "        return self.rag_chain.invoke({\"input\": question})\n",
    "\n",
    "    def save_index(self, path: str):\n",
    "        metadata = {\n",
    "            'embedding_model_name': self.embedding_model_name,\n",
    "            'chunk_size': self.chunk_size,\n",
    "            'chunk_overlap': self.chunk_overlap,\n",
    "            'export_type': self.export_type,\n",
    "            'persist_directory': self.persist_directory,\n",
    "            'num_documents': len(self.documents)\n",
    "        }\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(metadata, f)\n",
    "\n",
    "    def load_existing_vectorstore(self) -> bool:\n",
    "        try:\n",
    "            if os.path.exists(self.persist_directory):\n",
    "                self.vectorstore = Chroma(\n",
    "                    persist_directory=self.persist_directory,\n",
    "                    embedding_function=self.embeddings,\n",
    "                    collection_name=\"docling_rag\"\n",
    "                )\n",
    "                self.retriever = self.vectorstore.as_retriever()\n",
    "                return True\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load existing vector store: {e}\")\n",
    "            return False\n",
    "\n",
    "    def get_processed_files(self) -> set:\n",
    "        if self.vectorstore is None:\n",
    "            return set()\n",
    "        try:\n",
    "            collection = self.vectorstore._collection\n",
    "            results = collection.get(include=['metadatas'])\n",
    "            processed_files = set()\n",
    "            for metadata in results['metadatas']:\n",
    "                if 'source_file' in metadata:\n",
    "                    processed_files.add(metadata['source_file'])\n",
    "            return processed_files\n",
    "        except Exception:\n",
    "            return set()\n",
    "\n",
    "    def process_pdfs_incrementally(self, pdf_paths: _List[str]) -> _List[Document]:\n",
    "        self.load_existing_vectorstore()\n",
    "        processed_files = self.get_processed_files()\n",
    "        new_pdf_paths = []\n",
    "        for pdf_path in pdf_paths:\n",
    "            filename = os.path.basename(pdf_path)\n",
    "            if filename not in processed_files:\n",
    "                new_pdf_paths.append(pdf_path)\n",
    "        if not new_pdf_paths:\n",
    "            print(\"All PDFs already processed!\")\n",
    "            return []\n",
    "        new_docs = self.extract_documents_from_pdfs(new_pdf_paths)\n",
    "        if new_docs:\n",
    "            if self.vectorstore is None:\n",
    "                self.build_vector_store(new_docs)\n",
    "            else:\n",
    "                new_docs = filter_complex_metadata(new_docs)\n",
    "                new_docs = self._truncate_long_documents(new_docs)\n",
    "                self.vectorstore.add_documents(new_docs)\n",
    "                self.documents.extend(new_docs)\n",
    "        return new_docs\n",
    "\n",
    "# ===========================\n",
    "# Pipeline helpers\n",
    "# ===========================\n",
    "\n",
    "# Cache RAG instances per class to avoid reloading\n",
    "_RAG_CACHE: Dict[str, Optional[LangChainDoclingRAG]] = {}\n",
    "\n",
    "def _normalize_class_label(raw: str) -> str:\n",
    "    s = str(raw).strip().lower().replace(\"grade\", \"\").replace(\"class\", \"\").strip()\n",
    "    roman = {\"ix\": \"9\", \"x\": \"10\", \"xi\": \"11\", \"xii\": \"12\", \"viii\": \"8\", \"vii\": \"7\", \"vi\": \"6\"}\n",
    "    if s in roman:\n",
    "        s = roman[s]\n",
    "    digits = \"\".join(ch for ch in s if ch.isdigit())\n",
    "    if digits:\n",
    "        return f\"class_{digits}\"\n",
    "    return f\"class_{s.replace(' ', '_')}\"\n",
    "\n",
    "def load_rag_for_class(class_level: str,\n",
    "                       base_dir: str = \"rag\",\n",
    "                       embedding_model: str = \"sentence-transformers/all-MiniLM-L6-v2\") -> Optional[LangChainDoclingRAG]:\n",
    "    \"\"\"\n",
    "    Load (or reuse) a RAG instance pointing to the class-specific vector store.\n",
    "    Returns None if there is no existing vector store for that class.\n",
    "    \"\"\"\n",
    "    key = _normalize_class_label(class_level)\n",
    "    print(\"key is \" , key)\n",
    "    if key in _RAG_CACHE:\n",
    "        return _RAG_CACHE[key]\n",
    "\n",
    "    persist_dir = os.path.join(base_dir, key)\n",
    "    print(persist_dir)\n",
    "    rag = LangChainDoclingRAG(\n",
    "        embedding_model=embedding_model,\n",
    "        chunk_size=800,\n",
    "        chunk_overlap=100,\n",
    "        persist_directory=persist_dir\n",
    "    )\n",
    "\n",
    "    # Only load if persisted DB exists\n",
    "    if not os.path.exists(persist_dir):\n",
    "        _RAG_CACHE[key] = None\n",
    "        return None\n",
    "\n",
    "    if rag.load_existing_vectorstore():\n",
    "        _RAG_CACHE[key] = rag\n",
    "        return rag\n",
    "    else:\n",
    "        _RAG_CACHE[key] = None\n",
    "        return None\n",
    "\n",
    "# ---------------------------\n",
    "# Stage 1: extractor\n",
    "# ---------------------------\n",
    "import re\n",
    "def _get_output_text(resp) -> str:\n",
    "    # Works across SDK versions\n",
    "    try:\n",
    "        return resp.output_text\n",
    "    except AttributeError:\n",
    "        return resp.output[0].content[0].text\n",
    "\n",
    "def _parse_json_strict_or_repair(s: str) -> dict:\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "    # strip code fences if any\n",
    "    s2 = s.strip()\n",
    "    if s2.startswith(\"```\"):\n",
    "        s2 = re.sub(r\"^```[a-zA-Z0-9_-]*\\n|\\n```$\", \"\", s2, flags=re.S)\n",
    "    # fix illegal escapes like \\( \\frac \\theta -> \\\\( \\\\frac \\\\theta\n",
    "    s2 = re.sub(r'\\\\(?![\"\\\\/bfnrtu])', r'\\\\\\\\', s2)\n",
    "    return json.loads(s2)\n",
    "\n",
    "def process_one_stage1(user_input: str) -> dict:\n",
    "    try:\n",
    "        resp = client.responses.create(\n",
    "            model=\"gpt-4.1\",\n",
    "            input=user_input,\n",
    "           \n",
    "            # your stored prompt stays in extra_body\n",
    "            extra_body={\"prompt\": {\"id\": PROMPT_ID_STAGE1, \"version\": \"3\"}},\n",
    "        )\n",
    "        return _parse_json_strict_or_repair(_get_output_text(resp))\n",
    "    except Exception as e:\n",
    "        print(f\"Stage 1 request failed for '{user_input}': {e}\")\n",
    "        return {\"high_school\": {}}\n",
    "\n",
    "# ---------------------------\n",
    "# Build Stage 2 input\n",
    "# ---------------------------\n",
    "def build_context_input(hs_obj: Dict, rag_context: Optional[str]) -> str:\n",
    "    try:\n",
    "        main_topic = hs_obj.get(\"main_topic\", \"\")\n",
    "        context_object = hs_obj.get(\"context_object\", \"\")\n",
    "        concepts = [c.get(\"name\", \"\") for c in hs_obj.get(\"concepts\", [])]\n",
    "    except Exception:\n",
    "        main_topic, context_object, concepts = \"\", \"\", []\n",
    "\n",
    "    base = (\n",
    "        f\"Main Topic: {main_topic}\\n\"\n",
    "        f\"Context Object: {context_object}\\n\"\n",
    "        f\"Level: High School\\n\"\n",
    "        f\"Concepts: {concepts}\\n\"\n",
    "    )\n",
    "\n",
    "    if rag_context and rag_context.strip():\n",
    "        base += \"RAG_CONTEXT_BEGIN\\n\" + rag_context.strip() + \"\\nRAG_CONTEXT_END\\n\"\n",
    "    return base\n",
    "\n",
    "# ---------------------------\n",
    "# RAG retrieval helpers\n",
    "# ---------------------------\n",
    "def assemble_rag_query(hs_obj: Dict) -> str:\n",
    "    topic = hs_obj.get(\"main_topic\", \"\")\n",
    "    concept_names = [c.get(\"name\", \"\") for c in hs_obj.get(\"concepts\", [])]\n",
    "    top_concepts = \", \".join([c for c in concept_names if c][:10])\n",
    "    return f\"{topic}. Focus on: {top_concepts}\"\n",
    "\n",
    "def format_rag_context(results: List[Dict], max_chars: int = 2000) -> str:\n",
    "    parts = []\n",
    "    for i, r in enumerate(results, 1):\n",
    "        src = r.get(\"source\", \"Unknown\")\n",
    "        text = r.get(\"text\", \"\").strip().replace(\"\\n\", \" \")\n",
    "        snippet = text if len(text) <= 600 else text[:600] + \"...\"\n",
    "        parts.append(f\"[{i}] {snippet}\")\n",
    "    ctx = \"\\n\\n\".join(parts)\n",
    "    return ctx[:max_chars]\n",
    "\n",
    "def get_rag_context_for_class(class_level: str, hs_obj: Dict, top_k: int = 5) -> Optional[str]:\n",
    "    rag = load_rag_for_class(class_level)\n",
    "    if rag is None:\n",
    "        return None\n",
    "    query = assemble_rag_query(hs_obj)\n",
    "    try:\n",
    "        results = rag.search(query, top_k=1)\n",
    "        # print(\"rag results is \" , type(results))\n",
    "        if not results:\n",
    "            return None\n",
    "        return format_rag_context(results)\n",
    "    except Exception as e:\n",
    "        print(f\"RAG search failed for class '{class_level}': {e}\")\n",
    "        return None\n",
    "\n",
    "# ---------------------------\n",
    "# Stage 2: writer\n",
    "# ---------------------------\n",
    "def process_one_stage2(hs_wrapper: Dict, class_level: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Takes the Stage 1 output (which contains 'high_school') and class level,\n",
    "    fetches RAG context for that class, and calls your Stage 2 prompt.\n",
    "    \"\"\"\n",
    "    hs = hs_wrapper.get(\"high_school\", {})\n",
    "    print(hs)\n",
    "    rag_context = get_rag_context_for_class(class_level, hs)\n",
    "    print(\"rag type is \" , type(rag_context))\n",
    "    print(\"rag context is : \", rag_context)\n",
    "    ctx_input = build_context_input(hs, rag_context)\n",
    "    print(\"context input is : \", ctx_input)\n",
    "    # return \n",
    "    try:\n",
    "        resp = client.responses.create(\n",
    "            model=\"gpt-4.1\",\n",
    "            input=ctx_input,\n",
    "        \n",
    "            extra_body={\"prompt\": {\"id\": PROMPT_ID_STAGE2, \"version\": \"3\"}},\n",
    "        )\n",
    "        return _parse_json_strict_or_repair(_get_output_text(resp))\n",
    "    except Exception as e:\n",
    "        print(f\"Stage 2 request failed: {e}\")\n",
    "        return {\"concepts\": []}\n",
    "\n",
    "# ---------------------------\n",
    "# Orchestration\n",
    "# ---------------------------\n",
    "def build_slide_plans(inputs_with_class: List[Tuple[str, str]],\n",
    "                      max_workers: int = 5) -> Tuple[List[Dict], List[Dict]]:\n",
    "    \"\"\"\n",
    "    inputs_with_class: list of (user_prompt, class_level)\n",
    "    returns: (stage1_outputs, stage2_outputs)\n",
    "    \"\"\"\n",
    "    # Stage 1 in parallel\n",
    "    stage1_outputs: List[Dict] = [None] * len(inputs_with_class)\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "        fut_map = {ex.submit(process_one_stage1, q): i for i, (q, _cls) in enumerate(inputs_with_class)}\n",
    "        for fut in as_completed(fut_map):\n",
    "            idx = fut_map[fut]\n",
    "            stage1_outputs[idx] = fut.result()\n",
    "\n",
    "    # Stage 2 in parallel\n",
    "    print(\"Done Process 1 ---------------------------------------   \")\n",
    "    stage2_outputs: List[Dict] = [None] * len(inputs_with_class)\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "        fut_map = {\n",
    "            ex.submit(process_one_stage2, stage1_outputs[i], inputs_with_class[i][1]): i\n",
    "            for i in range(len(inputs_with_class))\n",
    "        }\n",
    "        for fut in as_completed(fut_map):\n",
    "            idx = fut_map[fut]\n",
    "            stage2_outputs[idx] = fut.result()\n",
    "\n",
    "    return stage1_outputs, stage2_outputs\n",
    "\n",
    "# ---------------------------\n",
    "# Example usage\n",
    "# ---------------------------\n",
    "\n",
    "# =====================================================================\n",
    "# Stage 3 (INTEGRATED): async image/code generator (your notebook agent)\n",
    "# =====================================================================\n",
    "\n",
    "# Tunables\n",
    "DEFAULT_MODEL_STAGE3 = os.getenv(\"OPENAI_MODEL_STAGE3\", MODEL_STAGE3)\n",
    "\n",
    "SYSTEM_INSTRUCTIONS_STAGE3 = \"\"\"\n",
    "You output STRICT JSON ONLY — a single JSON object with this schema:\n",
    "{\n",
    "  \"language\": \"python\" | \"latex\" | \"r\",\n",
    "  \"filename\": \"<str: .py for python, .tex/.tikz for LaTeX, .R for R>\",\n",
    "  \"code\": \"<full runnable code>\",\n",
    "  \"run_instructions\": \"<how to run/compile>\",\n",
    "  \"python_packages\": [\"...\"],\n",
    "  \"r_packages\": [\"...\"],\n",
    "  \"latex_requires\": [\"...\"]\n",
    "}\n",
    "\n",
    "Guidelines:\n",
    "- Choose the best language to produce a clear, self-contained FIGURE that illustrates the provided concept and explanation.\n",
    "- For PYTHON: use matplotlib + numpy; DO NOT use seaborn. Save an image (PNG or PDF) in the working directory.\n",
    "- For LaTeX: provide a fully compilable standalone .tex. Compiling with `pdflatex` should produce a PDF figure.\n",
    "- For R: use base or ggplot2; call `ggsave()` or similar to save an image.\n",
    "- No external data/files; everything self-contained.\n",
    "- The figure must be saved to the working directory with a sensible name.\n",
    "- Include minimal dependencies in the arrays.\n",
    "- Return ONLY valid JSON (no prose, no markdown, no backticks).\n",
    "\"\"\"\n",
    "\n",
    "USER_TEMPLATE_STAGE3 = \"\"\"\n",
    "Task: Generate runnable code to create ONE figure that best illustrates this concept for learners.\n",
    "\n",
    "Context:\n",
    "- Topic input: {topic_input}\n",
    "- Slide:\n",
    "  - id: {sid}\n",
    "  - name: {sname}\n",
    "  - detailed_explanation: {sexpl}\n",
    "\n",
    "Preferences:\n",
    "- Preferred language: auto (choose the best)\n",
    "- The code must save an image/PDF to the working directory.\n",
    "- Make the figure clean, labeled, and pedagogically useful.\n",
    "\n",
    "Return ONLY a single JSON object per the schema. Ensure the file extension matches the language.\n",
    "\"\"\"\n",
    "\n",
    "# ---- helpers ----\n",
    "def _ensure_dir(p: Path) -> None:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _validate_payload_stage3(d: Dict[str, Any]) -> str:\n",
    "    required = [\"language\", \"filename\", \"code\", \"run_instructions\",\n",
    "                \"python_packages\", \"r_packages\", \"latex_requires\"]\n",
    "    for k in required:\n",
    "        if k not in d:\n",
    "            raise ValueError(f\"Missing key in model JSON: {k}\")\n",
    "    lang = d[\"language\"].lower().strip()\n",
    "    fname = d[\"filename\"]\n",
    "    if lang == \"python\" and not fname.endswith(\".py\"):\n",
    "        raise ValueError(\"For python, filename must end with .py\")\n",
    "    if lang == \"latex\" and not (fname.endswith(\".tex\") or fname.endswith(\".tikz\")):\n",
    "        raise ValueError(\"For latex, filename must end with .tex or .tikz\")\n",
    "    if lang == \"r\" and not fname.endswith(\".R\"):\n",
    "        raise ValueError(\"For r, filename must end with .R\")\n",
    "    return lang\n",
    "\n",
    "async def _run_subprocess(cmd: List[str], cwd: Path, timeout: int = 300) -> Tuple[int, str, str]:\n",
    "    proc = await asyncio.create_subprocess_exec(\n",
    "        *cmd, cwd=str(cwd), stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE\n",
    "    )\n",
    "    try:\n",
    "        stdout, stderr = await asyncio.wait_for(proc.communicate(), timeout=timeout)\n",
    "    except asyncio.TimeoutError:\n",
    "        proc.kill()\n",
    "        return 124, \"\", f\"Timeout after {timeout}s\"\n",
    "    return proc.returncode, stdout.decode(errors=\"ignore\"), stderr.decode(errors=\"ignore\")\n",
    "\n",
    "async def _execute_generated_code(lang: str, workdir: Path, filename: str) -> Tuple[int, str, str]:\n",
    "    if lang == \"python\":\n",
    "        cmd = [\"python\", filename]\n",
    "        return await _run_subprocess(cmd, workdir)\n",
    "    if lang == \"r\":\n",
    "        cmd = [\"Rscript\", filename]\n",
    "        return await _run_subprocess(cmd, workdir)\n",
    "    if lang == \"latex\":\n",
    "        # compile twice\n",
    "        rc1, so1, se1 = await _run_subprocess([\"pdflatex\", \"-interaction=nonstopmode\", filename], workdir)\n",
    "        if rc1 != 0:\n",
    "            return rc1, so1, se1\n",
    "        rc2, so2, se2 = await _run_subprocess([\"pdflatex\", \"-interaction=nonstopmode\", filename], workdir)\n",
    "        return rc2, so1 + so2, se1 + se2\n",
    "    return 2, \"\", f\"Unsupported language: {lang}\"\n",
    "\n",
    "def _sanitize_name(s: str) -> str:\n",
    "    keep = \"\".join(c if c.isalnum() or c in (\"-\", \"_\") else \"_\" for c in s.strip())\n",
    "    return keep[:80] if keep else \"untitled\"\n",
    "\n",
    "def _slide_dir(base: Path, topic: str, slide_id: Any, slide_name: str) -> Path:\n",
    "    tdir = _sanitize_name(topic)\n",
    "    sdir = f\"{str(slide_id).zfill(2)}_{_sanitize_name(slide_name)}\"\n",
    "    return base / tdir / sdir\n",
    "\n",
    "def _extract_saved_files(workdir: Path) -> List[str]:\n",
    "    exts = {\".png\", \".pdf\", \".jpg\", \".jpeg\", \".svg\"}\n",
    "    return [f.name for f in workdir.iterdir() if f.is_file() and f.suffix.lower() in exts]\n",
    "\n",
    "# ---- one figure task ----\n",
    "async def _gen_one_figure(\n",
    "    client_async: AsyncOpenAI,\n",
    "    semaphore: asyncio.Semaphore,\n",
    "    model: str,\n",
    "    topic_input: str,\n",
    "    slide: Dict[str, Any],\n",
    "    outdir: Path,\n",
    "    attempt: int = 0,\n",
    "    max_attempts: int = 3\n",
    ") -> Dict[str, Any]:\n",
    "    sid   = slide.get(\"id\", \"NA\")\n",
    "    sname = slide.get(\"name\", \"Concept\")\n",
    "    sexpl = slide.get(\"detailed_explanation\", \"\")\n",
    "\n",
    "    workdir = _slide_dir(outdir, topic_input, sid, sname)\n",
    "    _ensure_dir(workdir)\n",
    "\n",
    "    user_msg = USER_TEMPLATE_STAGE3.format(\n",
    "        topic_input=topic_input, sid=sid, sname=sname, sexpl=sexpl\n",
    "    )\n",
    "\n",
    "    backoff = 2 ** attempt\n",
    "    async with semaphore:\n",
    "        if attempt > 0:\n",
    "            await asyncio.sleep(backoff)\n",
    "        try:\n",
    "            resp = await client_async.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_INSTRUCTIONS_STAGE3},\n",
    "                    {\"role\": \"user\", \"content\": user_msg},\n",
    "                ],\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "            )\n",
    "        except Exception as e:\n",
    "            err = f\"OpenAI API error (attempt {attempt+1}/{max_attempts}): {e}\"\n",
    "            if attempt + 1 < max_attempts:\n",
    "                return await _gen_one_figure(client_async, semaphore, model, topic_input, slide, outdir, attempt+1, max_attempts)\n",
    "            return {\"ok\": False, \"topic\": topic_input, \"slide_id\": sid, \"slide_name\": sname, \"error\": err}\n",
    "\n",
    "    content = resp.choices[0].message.content\n",
    "    try:\n",
    "        data = json.loads(content)\n",
    "        lang = _validate_payload_stage3(data)\n",
    "    except Exception as e:\n",
    "        err = f\"Bad JSON or schema (attempt {attempt+1}/{max_attempts}): {e}\\n{content}\"\n",
    "        if attempt + 1 < max_attempts:\n",
    "            return await _gen_one_figure(client_async, semaphore, model, topic_input, slide, outdir, attempt+1, max_attempts)\n",
    "        return {\"ok\": False, \"topic\": topic_input, \"slide_id\": sid, \"slide_name\": sname, \"error\": err}\n",
    "\n",
    "    # Write code file\n",
    "    codefile = workdir / data[\"filename\"]\n",
    "    codefile.write_text(data[\"code\"].rstrip() + \"\\n\", encoding=\"utf-8\")\n",
    "\n",
    "    # Execute it\n",
    "    rc, so, se = await _execute_generated_code(lang, workdir, codefile.name)\n",
    "    images = _extract_saved_files(workdir)\n",
    "\n",
    "    return {\n",
    "        \"ok\": rc == 0 and len(images) > 0,\n",
    "        \"topic\": topic_input,\n",
    "        \"slide_id\": sid,\n",
    "        \"slide_name\": sname,\n",
    "        \"workdir\": str(workdir),\n",
    "        \"language\": lang,\n",
    "        \"filename\": codefile.name,\n",
    "        \"run_exit_code\": rc,\n",
    "        \"stdout\": so,\n",
    "        \"stderr\": se,\n",
    "        \"saved_artifacts\": images,\n",
    "        \"model_json\": data\n",
    "    }\n",
    "\n",
    "# ---- public async runner ----\n",
    "async def stage3_run_async(\n",
    "    items: List[Dict[str, Any]],\n",
    "    outdir: str,\n",
    "    model: str,\n",
    "    max_parallel: int\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \n",
    "    client_async = AsyncOpenAI(api_key='sk-proj--Br-2ucFM_qeDf2qH_QZfp30GMqhQCG5svK4A')\n",
    "\n",
    "    sem = asyncio.Semaphore(max_parallel)\n",
    "    base = Path(outdir).resolve()\n",
    "    _ensure_dir(base)\n",
    "\n",
    "    tasks = []\n",
    "    for item in items:\n",
    "        topic = item[\"input\"]\n",
    "        for slide in item[\"concepts\"]:\n",
    "            tasks.append(_gen_one_figure(client_async, sem, model, topic, slide, base))\n",
    "\n",
    "    results = []\n",
    "    for fut in asyncio.as_completed(tasks):\n",
    "        res = await fut\n",
    "        tag = f\"[{res.get('topic','?')}] slide={res.get('slide_id','?')} «{res.get('slide_name','')}»\"\n",
    "        if res.get(\"ok\"):\n",
    "            print(f\"✓ Generated: {tag}  ->  {res.get('workdir')}\")\n",
    "        else:\n",
    "            print(f\"✗ Failed:    {tag}  ->  {res.get('error','unknown error')}\", file=sys.stderr)\n",
    "        results.append(res)\n",
    "    return results\n",
    "\n",
    "# ---------------------------\n",
    "# Glue: feed Stage-2 -> Stage-3\n",
    "# ---------------------------\n",
    "def stage3_items_from_stage2(\n",
    "    inputs_with_class: List[Tuple[str, str]],\n",
    "    stage1_outputs: List[Dict],\n",
    "    stage2_outputs: List[Dict]\n",
    ") -> List[Dict[str, Any]]:\n",
    "    items: List[Dict[str, Any]] = []\n",
    "    for i, (topic, _cls) in enumerate(inputs_with_class):\n",
    "        # prefer Stage-2 concepts; fallback to Stage-1 scaffold if needed\n",
    "        concepts = stage2_outputs[i].get(\"concepts\") or stage1_outputs[i].get(\"high_school\", {}).get(\"concepts\") or []\n",
    "        items.append({\"input\": topic, \"concepts\": concepts})\n",
    "    return items\n",
    "\n",
    "# ---------------------------\n",
    "# Modification: Stage-3 -> Stage-4\n",
    "# ---------------------------\n",
    "\n",
    "def _encode_image_as_data_url(img_path: Path) -> str:\n",
    "    \"\"\"Return a data:image/...;base64 URL that Chat Completions API can ingest as an input image.\"\"\"\n",
    "    ext = img_path.suffix.lower().lstrip(\".\")\n",
    "    if ext not in {\"png\", \"jpg\", \"jpeg\", \"webp\"}:\n",
    "        ext = \"png\"\n",
    "    data = img_path.read_bytes()\n",
    "    b64 = base64.b64encode(data).decode(\"utf-8\")\n",
    "    return f\"data:image/{ext};base64,{b64}\"\n",
    "\n",
    "def _load_last_run_summary(summary_path: Path) -> List[Dict[str, Any]]:\n",
    "    if not summary_path.exists():\n",
    "        raise FileNotFoundError(f\"summary_results.json not found at {summary_path}\")\n",
    "    return json.loads(summary_path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "def _find_slide_entry(summary: List[Dict[str, Any]], slide_id: int, image_name: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Use summary_results.json (Stage-3 output) to locate the slide's working directory\n",
    "    and verify that the requested image exists there.\n",
    "    \"\"\"\n",
    "    # prefer exact id match; if multiple entries share id, pick the first where image exists\n",
    "    for entry in summary:\n",
    "        if entry.get(\"slide_id\") == slide_id:\n",
    "            wd = Path(entry[\"workdir\"])\n",
    "            candidate = wd / image_name\n",
    "            if candidate.exists():\n",
    "                entry[\"_image_path\"] = str(candidate)\n",
    "                return entry\n",
    "    # fallback: search all entries for the image\n",
    "    for entry in summary:\n",
    "        wd = Path(entry[\"workdir\"])\n",
    "        candidate = wd / image_name\n",
    "        if candidate.exists():\n",
    "            entry[\"_image_path\"] = str(candidate)\n",
    "            return entry\n",
    "    raise FileNotFoundError(f\"Could not find image '{image_name}' for slide id={slide_id}.\")\n",
    "\n",
    "# ------ Stage 4: modification (code regeneration from existing image + edit request) ------\n",
    "# Reuse Stage-3 SYSTEM_INSTRUCTIONS_STAGE3\n",
    "MOD_USER_TEMPLATE = \"\"\"\n",
    "You are given an existing slide figure (provided below as an image) that was generated for:\n",
    "- Topic: {topic}\n",
    "- Slide id: {sid}\n",
    "- Slide name: {sname}\n",
    "\n",
    "Modify the figure according to these instructions:\n",
    "\n",
    "MODIFICATION_REQUEST:\n",
    "{mod_instructions}\n",
    "\n",
    "Constraints and goals:\n",
    "- Output STRICT JSON ONLY with the same schema used previously (language, filename, code, run_instructions, python_packages, r_packages, latex_requires).\n",
    "- Produce new code that recreates the original figure BUT with the requested modifications applied.\n",
    "- If the original appears to be matplotlib: keep matplotlib + numpy (no seaborn). If LaTeX: return a fully compilable .tex. If R: use base/ggplot2.\n",
    "- Ensure the code SAVES the final figure to the working directory. Use a new filename that includes '_modified' before the extension.\n",
    "- Keep dependencies minimal.\n",
    "\n",
    "Return only the JSON object; no extra text.\n",
    "\"\"\"\n",
    "\n",
    "def _propose_modified_code_from_image(\n",
    "    client_sync: OpenAI,\n",
    "    model: str,\n",
    "    image_path: Path,\n",
    "    topic: str,\n",
    "    slide_id: Any,\n",
    "    slide_name: str,\n",
    "    mod_instructions: str\n",
    ") -> Dict[str, Any]:\n",
    "    data_url = _encode_image_as_data_url(image_path)\n",
    "    user_msg = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": MOD_USER_TEMPLATE.format(\n",
    "                topic=topic, sid=slide_id, sname=slide_name, mod_instructions=mod_instructions).strip()},\n",
    "            {\"type\": \"input_image\", \"image_url\": {\"url\": data_url}}\n",
    "        ]\n",
    "    }\n",
    "    resp = client_sync.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_INSTRUCTIONS_STAGE3.strip()},\n",
    "            user_msg\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "    payload = resp.choices[0].message.content\n",
    "    data = json.loads(payload)\n",
    "    _ = _validate_payload_stage3(data)  # will raise if invalid / mismatched extension\n",
    "    return data\n",
    "\n",
    "async def _execute_stage4_and_save(\n",
    "    data: Dict[str, Any],\n",
    "    workdir: Path\n",
    ") -> Tuple[int, str, str, List[str]]:\n",
    "    codefile = workdir / data[\"filename\"]\n",
    "    # ensure unique filename if needed\n",
    "    if codefile.exists():\n",
    "        stem, suf = codefile.stem, codefile.suffix\n",
    "        codefile = workdir / f\"{stem}_{int(datetime.now().timestamp())}{suf}\"\n",
    "    codefile.write_text(data[\"code\"].rstrip() + \"\\n\", encoding=\"utf-8\")\n",
    "    rc, so, se = await _execute_generated_code(data[\"language\"].lower(), workdir, codefile.name)\n",
    "    images = _extract_saved_files(workdir)\n",
    "    return rc, so, se, images\n",
    "\n",
    "def _append_mod_log(base_outdir: Path, record: Dict[str, Any]) -> None:\n",
    "    logf = base_outdir / \"modifications.jsonl\"\n",
    "    with logf.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example: topic + class\n",
    "    inputs_with_class: List[Tuple[str, str]] = [\n",
    "        (\"explain me projectile motion using cricket\", \"10\"),\n",
    "    ]\n",
    "\n",
    "    stage1, stage2 = build_slide_plans(inputs_with_class, max_workers=5)\n",
    "\n",
    "    temp = []\n",
    "\n",
    "    for i , input_text in enumerate(inputs_with_class):\n",
    "\n",
    "        for slide in stage2[i]['concepts']:\n",
    "            temp.append(slide)\n",
    "            break\n",
    "\n",
    "    stage2[0]['concepts'] = temp\n",
    "\n",
    "    # Display results\n",
    "    for i, input_text in enumerate(inputs_with_class):\n",
    "        print(\"\\n\\n\")\n",
    "        print(\"========================================\")\n",
    "        print(f\"Input: {input_text}\")\n",
    "        print(\"========================================\")\n",
    "        for slide in stage2[i]['concepts']:\n",
    "            print('-'*200)\n",
    "            # print(f\" - {slide}\")\n",
    "            print(f'\\tSlide No. - {slide['id']}')\n",
    "            print(f'\\tName : {slide['name']}')\n",
    "            print(f'\\tDetailed Explantion :-\\n\\t{slide['detailed_explanation']}')\n",
    "            print('-'*200)\n",
    "    items = stage3_items_from_stage2(inputs_with_class, stage1, stage2)\n",
    "\n",
    "    # Ensure outdir exists\n",
    "    Path(OUTDIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Run Stage 3 (async) and persist summary\n",
    "    try:\n",
    "        # Notebook-friendly: allow nested loops if present\n",
    "        try:\n",
    "            import nest_asyncio\n",
    "            nest_asyncio.apply()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        loop = asyncio.get_event_loop()\n",
    "        results = loop.run_until_complete(\n",
    "            stage3_run_async(items, OUTDIR, DEFAULT_MODEL_STAGE3, MAX_PARALLEL_STAGE3)\n",
    "        )\n",
    "    except RuntimeError:\n",
    "        # Fallback for environments without a running loop\n",
    "        results = asyncio.run(stage3_run_async(items, OUTDIR, DEFAULT_MODEL_STAGE3, MAX_PARALLEL_STAGE3))\n",
    "\n",
    "    summary_path = Path(OUTDIR) / \"summary_results.json\"\n",
    "    summary_path.write_text(json.dumps(results, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    ok = [r for r in results if r.get(\"ok\")]\n",
    "    bad = [r for r in results if not r.get(\"ok\")]\n",
    "    print(f\"\\n[✓] Finished. OK: {len(ok)}  Failed: {len(bad)}  (details: {summary_path})\")\n",
    "\n",
    "    # Minimal demo print\n",
    "    for i, (inp, cls) in enumerate(inputs_with_class):\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"INPUT: {inp!r}  |  CLASS: {cls}\")\n",
    "        print(\"- Stage 1 (scaffold) keys:\", list(stage1[i].get(\"high_school\", {}).keys()))\n",
    "        print(\"- Stage 2 (expanded) keys:\", list(stage2[i].keys()))\n",
    "\n",
    "        # ------------------------- Stage 4: Optional modifications -------------------------\n",
    "    # Read the last run summary; offer interactive edits.\n",
    "    client_sync = OpenAI()  # reads OPENAI_API_KEY from env\n",
    "    summary = _load_last_run_summary(summary_path)\n",
    "\n",
    "    print(\"\\n--- Stage 4: Modify generated slide images (optional) ---\")\n",
    "    print(\"You can edit slides by giving (slide id) and (image filename), e.g., '1 projectile_motion_cricket.png'.\")\n",
    "    print(\"Leave slide id empty to finish.\\n\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            raw = input(\"Enter: <slide_id> <image_name> (or blank to exit): \").strip()\n",
    "        except EOFError:\n",
    "            break\n",
    "        if not raw:\n",
    "            break\n",
    "\n",
    "        parts = raw.split()\n",
    "        if len(parts) < 2:\n",
    "            print(\"Please provide both slide id and image filename.\")\n",
    "            continue\n",
    "        try:\n",
    "            slide_id = int(parts[0])\n",
    "        except ValueError:\n",
    "            print(\"Slide id must be an integer (the numeric id shown in your slides).\")\n",
    "            continue\n",
    "        image_name = \" \".join(parts[1:])\n",
    "\n",
    "        mod_instructions = input(\"Describe the modification you want: \").strip()\n",
    "        if not mod_instructions:\n",
    "            print(\"No modification text provided; skipping.\")\n",
    "            continue\n",
    "\n",
    "        # locate the slide and its directory from the summary\n",
    "        try:\n",
    "            entry = _find_slide_entry(summary, slide_id, image_name)\n",
    "        except FileNotFoundError as e:\n",
    "            print(str(e))\n",
    "            continue\n",
    "\n",
    "        image_path = Path(entry[\"_image_path\"])\n",
    "        workdir = Path(entry[\"workdir\"])\n",
    "        topic   = entry.get(\"topic\", \"unknown topic\")\n",
    "        sname   = entry.get(\"slide_name\", f\"slide_{slide_id}\")\n",
    "\n",
    "        print(f\"\\n→ Modifying slide {slide_id} «{sname}» with image {image_path.name}\")\n",
    "        try:\n",
    "            data = _propose_modified_code_from_image(\n",
    "                client_sync=client_sync,\n",
    "                model=DEFAULT_MODEL_STAGE3,   # reuse your Stage-3 model\n",
    "                image_path=image_path,\n",
    "                topic=topic,\n",
    "                slide_id=slide_id,\n",
    "                slide_name=sname,\n",
    "                mod_instructions=mod_instructions\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Model failed to produce valid JSON: {e}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # execute and collect artifacts\n",
    "            # reuse your asyncio loop pattern safely\n",
    "            try:\n",
    "                loop = asyncio.get_event_loop()\n",
    "                rc, so, se, images = loop.run_until_complete(_execute_stage4_and_save(data, workdir))\n",
    "            except RuntimeError:\n",
    "                rc, so, se, images = asyncio.run(_execute_stage4_and_save(data, workdir))\n",
    "\n",
    "            ok = (rc == 0)\n",
    "            print(f\"Execution {'succeeded' if ok else 'failed'} (exit={rc}). Saved files: {images}\")\n",
    "            # log the modification\n",
    "            _append_mod_log(Path(OUTDIR), {\n",
    "                \"ts\": datetime.now().isoformat(),\n",
    "                \"topic\": topic,\n",
    "                \"slide_id\": slide_id,\n",
    "                \"slide_name\": sname,\n",
    "                \"workdir\": str(workdir),\n",
    "                \"source_image\": image_path.name,\n",
    "                \"mod_instructions\": mod_instructions,\n",
    "                \"model_json\": data,\n",
    "                \"run_exit_code\": rc,\n",
    "                \"stdout\": so[-5000:],  # avoid giant logs\n",
    "                \"stderr\": se[-5000:],\n",
    "                \"final_artifacts\": images\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Could not execute modified code: {e}\")\n",
    "\n",
    "    print(\"\\n[Stage 4] done.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "extramarks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
